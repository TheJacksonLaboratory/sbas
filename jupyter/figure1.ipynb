{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1C - YARN Normalization Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `heatplot` representing similarity in the fold-changes between male and female samples, with the values in the heatmap being the correlation between the vectors of fold changes of the tissues. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NOTE**:\n",
    "\n",
    "We assume that you have cloned the analysis repository and have `cd` into the parent directory. Before starting with the analysis make sure you have first completed the dependencies set up by following the instructions described in the **`dependencies/README.md`** document. All paths defined in this Notebook are relative to the parent directory (repository). Please close this Notebook and start again by following the above guidelines if you have not completed the aforementioned steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(snakecase): there is no package called ‘snakecase’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(snakecase): there is no package called ‘snakecase’\nTraceback:\n",
      "1. library(snakecase)"
     ]
    }
   ],
   "source": [
    "library(downloader)\n",
    "library(readr)\n",
    "library(edgeR)\n",
    "library(biomaRt)\n",
    "library(DBI) # v >= 1.1.0 required for biomaRt\n",
    "library(devtools)\n",
    "library(yarn)\n",
    "library(statmod)\n",
    "library(piggyback)\n",
    "library(snakecase)\n",
    "library(stringr)\n",
    "library(pheatmap)\n",
    "library(magrittr)\n",
    "Sys.setenv(TAR = \"/bin/tar\") # for gzfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving the GTEx archive\n",
    "\n",
    "We used the R package [{yarn}](https://bioconductor.org/packages/release/bioc/html/yarn.html) to retrieve the GTEx Biobank data. In order to downloaded the latest GTEx version 8.0 for RNA-seq and genotype data (phs000424.v8.v2), released 2019-08-26, we created a fork of the package's GitHub repository and created a new version of the function **`yarn::downloadGTEx()`**, namely **`yarn::downloadGTExV8()`** to download this release. \n",
    "\n",
    "We used the function to perform quality control, gene filtering and normalization pre-processing on the GTEx RNA-seq data, as described in (Paulson et al, 2017). This pipeline tested for sample sex-misidentification, merged related sub-tissues and performed tissue-aware normalization using the **`{yarn::qsmooth}`**  function (Hicks et al, 2017).\n",
    "\n",
    "We have archived the output of the **`yarn::downloadGTExV8()`** function, which is an `ExpressionSet` object in the repo `lifebitai/lifebitCloudOSDREgtex` for replicability and decreasing the runtime of this analysis. Below we retrieve this `gtex.rds` object from the GitHub releases using the **`{ropensci/piggyback}`** package, but we have also added the relevant command to retrieve the data from GTEx and generate the `ExpressionSet` object using  **`yarn::downloadGTExV8()`**. For the current analysis we are utilising a compute resource with 8 vCPUs and 60 GB of memory available.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with readRDS() if gtex.rds available in data/\n",
    "if (\"gtex.rds\" %in% list.files(\"../data/\")) {\n",
    "    message(\"Loading GTEx v8 rds object with readRDS from ../data/gtex.rds ..\\n\")   \n",
    "    obj <- readRDS(file = \"../data/gtex.rds\" )\n",
    "    message(\"Done!\\n\")\n",
    "    message(\"Generating sha256sum for gtex.rds ..\\n\")    \n",
    "    message(system(\"sha256sum ../data/gtex.rds\", intern = TRUE))\n",
    "    message(\"Done!\\n\")\n",
    "}\n",
    "\n",
    "# Download from archive if not available in ../data\n",
    "if (!(\"gtex.rds\" %in% list.files(\"../data/\"))) {\n",
    "    message(\"Downloading GTEx v8 from GitHub Releases archive into the ../data/ directory ..\\n\")\n",
    "    piggyback::pb_download(file = \"gtex.rds\", \n",
    "                                repo = \"lifebit-ai/lifebitCloudOSDREgtex\", \n",
    "                                tag  = \"fig1c_archive\", \n",
    "                                dest = \"../data/\")\n",
    "    message(\"Generating sha256sum for gtex.rds ..\")    \n",
    "    message(system(\"sha256sum ../data/gtex.rds\", intern = TRUE))\n",
    "    message(\"Done!\\n\")    \n",
    "    message(\"Loading GTEx v8 rds object with readRDS from ../data/gtex.rds ..\\n\")    \n",
    "    obj <- readRDS(file = \"../data/gtex.rds\" )\n",
    "    message(\"Done!\\n\")\n",
    "}\n",
    "\n",
    "# Download with yarn if you wish, this requires several minutes to complete\n",
    "if (!(\"gtex.rds\" %in% list.files(\"../data/\"))) {\n",
    "    message(\"Downloading GTEx v8 with 'yarn::downloadGTExV8()'\")\n",
    "    obj <- yarn::downloadGTExV8(type='genes',file='../data/gtex.rds')\n",
    "    message(\"Done!\")\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that it is an expression set.\n",
    "# and check the dimensions of the objects, and the phenotype information of the objects\n",
    "class(obj) \n",
    "dim(phenoData(obj))\n",
    "dim(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: \n",
    "\n",
    "We observe above that our phenotype data have 2 more observations than our expression data,  let's inspect what are these samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names=as.vector(as.character(colnames(exprs(obj))))\n",
    "length(sample_names)\n",
    "\n",
    "pheno_sample_names=as.vector(as.character(rownames(pData(obj))))\n",
    "length(pheno_sample_names)\n",
    "\n",
    "if (length(pheno_sample_names) > length(sample_names)) {\n",
    "    superset <- pheno_sample_names\n",
    "    subset   <- sample_names    \n",
    "} \n",
    "\n",
    "if (length(pheno_sample_names) < length(sample_names)) {\n",
    "    superset <- sample_names\n",
    "    subset   <- pheno_sample_names   \n",
    "} \n",
    "\n",
    "non_overlaps <- setdiff( superset, subset)\n",
    "\n",
    "message(\"The non-overlapping IDs between pheno and count data are:\\n\\n\", \n",
    "        paste(non_overlaps, collapse = \"\\n\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep only the overlapping IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_match_names=pheno_sample_names %in% sample_names\n",
    "length(logical_match_names)\n",
    "table(logical_match_names)\n",
    "pData(obj) <- (pData(obj)[logical_match_names==TRUE,])\n",
    "dim(pData(obj))\n",
    "dim(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Now we want to replace all *dashes* with **dots \".\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pData(obj)$SAMPID[1]\n",
    "pData(obj)$SAMPID <- gsub('-','\\\\.',pData(obj)$SAMPID)\n",
    "pData(obj)$SAMPID[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(pData(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(exprs(obj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Differential Expression using `{edgeR}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_counts_matrix <- exprs(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(transcript_counts_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the **`edgeR::DGEList()`** function, we need to transpose our `transcript_counts_matrix` so that the length of group is equal to the number of columns in our counts (`transcript_counts_matrix`). You will get an error from the   **`edgeR::DGEList()`** function (counts = x, group = group) if the length of group is not equal to the number of columns in counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group <- factor(pData(obj)$SEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: \n",
    "\n",
    "This step takes several minutes to complete. If you have **not** applied other filtering options or you are coming back to your analysis and want to continue from this step, feel free to use the cached version using the following command:\n",
    "\n",
    "```\n",
    "# Load with readRDS() if `../data/DGENormFactorsy.rds` available in data/\n",
    "if (\"DGENormFactorsy.rds\" %in% list.files(\"../data/\")) {\n",
    "    message(\"Loading  `../data/DGENormFactorsy.rds` object with `readRDS()` from ../data/ \\n\")    \n",
    "    y <- readRDS(\"../data/DGENormFactorsy.rds\")\n",
    "    message(\"Done!\")    \n",
    "}\n",
    "```\n",
    "\n",
    "By default, these objects will be regenarated the making sure the changes from above are applied to these objects as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download if not available in ../data\n",
    "if (!(\"DGENormFactorsy.rds\" %in% list.files(\"../data/\"))) {\n",
    "    message(\"Creating `DGEList` object from counts matrix with 'edgeR::DGEList()' ..\")\n",
    "    y <- edgeR::DGEList(counts = transcript_counts_matrix, \n",
    "                        group  = group)\n",
    "    message(\"Done!\\n\")    \n",
    "\n",
    "    message(\"Calculating normalization factors on `DGEList` object to scale the raw library sizes with 'edgeR::DGEList()' ..\")    \n",
    "    y <- edgeR::calcNormFactors(y)\n",
    "    message(\"Done!\\n\")    \n",
    "    message(\"Saving normalization factors object in '../data/DGENormFactorsy.rds' ..\")        \n",
    "    saveRDS(y, file = \"../data/DGENormFactorsy.rds\")\n",
    "    message(\"Done!\\n\")    \n",
    "    message(\"Generating sha256sum for DGENormFactorsy.rds ..\\n\")    \n",
    "    message(system(\"sha256sum ../data/DGENormFactorsy.rds\", intern = TRUE))\n",
    "    message(\"Done!\\n\")\n",
    "}\n",
    "\n",
    "attributes(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(y$counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Guy -- does this do what you are expecting -- I am confused because what you get when you\n",
    "#        ask for the min (table(groups)) is the smaller sized group -- which in this case is \n",
    "#        female -- it will help the reader to know what you are doing here with the statement.\n",
    "#        one can read what it is doing but not understand your objective.groups <- pData(obj)$SEX\n",
    "# keep.events <- rep(TRUE, nrow(y))\n",
    "# for (group in c(1,2)) {\n",
    "#    keep.events <- keep.events & \n",
    "#                   rowSums(cpm(y[,groups %in% group]) > 1) >= 0.25*min(table(groups))\n",
    "# }\n",
    "\n",
    "#  From Anne - I believe the objective in this step is to keep only those genes that are in the\n",
    "#    that are above the threshold of expression for the lower quartile of all sex specific genes.\n",
    "#    groups = (1,2) -- lots of confusion in logic between groups and group and male and female\n",
    "#    I recommend we use male and female.\n",
    "#    two errors then in the above loop - \n",
    "#     1. min(table(groups)) will always return the\n",
    "#        length of the number of samples that are female \n",
    "#        (which is 5978 for this v8 GTEx)\n",
    "#     2. sum(table(group)) will return the number of samples that are either male or female\n",
    "#        depending upon whether you are in the loop for male or female consideration.\n",
    "\n",
    "#    If my assumption is true - I recommend replacing it with the following.\n",
    "\n",
    "#  this should be replaced \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep.events <- rep(TRUE, nrow(y))\n",
    "nrow(y)\n",
    "table(pData(obj)$SEX)\n",
    "table(group)\n",
    "#\n",
    "# first keep all the events for the male subsets meeting our threshold criteria\n",
    "#\n",
    "keep.events  <- keep.events & rowSums(edgeR::cpm(y$counts[,group == 1]) > 1) >= 0.25*length(group==1)\n",
    "#\n",
    "# now keep all the male subsets or the female subsets meeting our criteria\n",
    "#\n",
    "keep.events2 <- keep.events | rowSums(edgeR::cpm(y$counts[,group == 2]) > 1) >= 0.25*length(group==2)\n",
    "table(keep.events)\n",
    "table(keep.events2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with readRDS() if `../data/reduced_y.rds` available in data/\n",
    "if  ( ('reduced_y.rds' %in% list.files(\"../data/\")) && ('reduced_obj' %in% list.files(\"../data/\"))) {\n",
    "    message(\"Loading  `reduced_y.rds` and  `reduced_obj` objects with `readRDS()` from ../data/ \\n\")    \n",
    "    reduced_obj <- readRDS(file = \"../data/reduced_obj.rds\")\n",
    "    reduced_y   <- readRDS(file = \"../data/reduced_y.rds\")\n",
    "    message(\"Done!\")    \n",
    "}\n",
    "\n",
    "\n",
    "# Create if not available in ../data\n",
    "if  ( !(('reduced_y.rds' %in% list.files(\"../data/\")) && ('reduced_obj' %in% list.files(\"../data/\")))) {\n",
    "\n",
    "    message(\"Creating `reduced_y` keeping only rows that match `keep.events2` list ..\")\n",
    "    reduced_y<- y[keep.events2,]\n",
    "    message(\"Done!\\n\")    \n",
    "    \n",
    "    message(\"Creating `reduced_obj` keeping only rows that match `keep.events2` list ..\")    \n",
    "    reduced_obj <- obj[keep.events2==TRUE,]\n",
    "    message(\"Done!\\n\")    \n",
    "    \n",
    "    message(\"Saving `reduced_y.rds`, `reduced_obj.rds` in '../data/' ..\")        \n",
    "    saveRDS(reduced_y, file = \"../data/reduced_y.rds\")\n",
    "    saveRDS(reduced_obj, file = \"../data/reduced_obj.rds\")\n",
    "    message(\"Done!\\n\")     \n",
    "}\n",
    "\n",
    "dim(reduced_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the analysis by male and by female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_male   <- pData(reduced_obj)$SEX==1\n",
    "reduced_female <- pData(reduced_obj)$SEX==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_obj_male   <- reduced_obj[,reduced_male==TRUE]\n",
    "reduced_obj_female <- reduced_obj[,reduced_female==TRUE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(reduced_obj_male)\n",
    "dim(reduced_obj_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing from SMTS to SMTSD - more granularity -- but we could produce both figures\n",
    "tissue_groups_male <- factor(pData(reduced_obj_male)$SMTSD)\n",
    "tissue_groups_female <- factor(pData(reduced_obj_female)$SMTSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good sanity check, the male set does not have any vaginas or uterus\n",
    "table (tissue_groups_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the females have no prostate or testis\n",
    "table(tissue_groups_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducing previous results using the `yarn` expression object, loop through the tissues and for those tissues that are shared between the two sexes perform a differential gene analysis on a per tissue basis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_groups <- factor(pData(reduced_obj)$SMTSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_male_female <- tissue_groups_male %in% tissue_groups_female\n",
    "table(tissue_male_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_shared_male_female <- factor(tissue_groups_male[tissue_male_female])\n",
    "table(tissue_shared_male_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEX is coded 1 == Male\n",
    "#              2 == Female\n",
    "sex = factor(pData(reduced_obj)$SEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define a function named `fit_tissue()`that accepts two arguments, the `tissue` and an `object` and create the **model matrix** based  that tissue's sex. We will perform a linear fit after calculating normal factors (based on the library size) and calculate the dispersion using `{voom}` (mean variance model of dispersion). We are saving the resulting matrixes as files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_tissue <- function (tissue, obj) {\n",
    "    tissue_true    <- pData(obj)$SMTSD == tissue\n",
    "    tissue_obj     <- obj[,tissue_true ==TRUE]\n",
    "    tissue_sex     <- factor(pData(tissue_obj)$SEX)\n",
    "    tissue_design  <- model.matrix(~tissue_sex)\n",
    "    y_tissue       <- DGEList(counts=exprs(tissue_obj), group=tissue_sex)\n",
    "    y_tissue       <- calcNormFactors(y_tissue)\n",
    "    y_tissue_voom  <- voom(y_tissue, tissue_design)\n",
    "    fit_tissue     <- lmFit(y_tissue_voom, tissue_design)\n",
    "    fit_tissue     <- eBayes(fit_tissue, robust=TRUE)\n",
    "    results_tissue <- topTable (fit_tissue, coef='tissue_sex2', number=nrow(y_tissue))\n",
    "    filename = paste(paste(\"../data\",gsub(\" \",\"\",tissue), sep=\"/\"),\"DGE.csv\", sep=\"_\")    \n",
    "    write.table(results_tissue, filename, sep=',', quote=FALSE)\n",
    "    return (results_tissue)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging with using the 'Thyroid' tissue\n",
    "#thyroid_logFC <- fit_tissue('Thyroid',reduced_obj)\n",
    "#thyroid_logFC\n",
    "# \n",
    "all_logFC <- lapply(X=levels(tissue_shared_male_female), FUN=fit_tissue, obj=reduced_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames <- list.files(\"../data\", pattern=\"*_DGE.csv\", all.files=FALSE, full.names=TRUE)\n",
    "(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve the ordered rownames for later assignment to matrix\n",
    "fullfilename <-filenames[1]\n",
    "logFC_mat    <- read.csv(fullfilename)\n",
    "logFC_mat    <- logFC_mat[order(rownames(logFC_mat)),]\n",
    "logFC_mat_rownames <- as.character(rownames(logFC_mat)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a matrix for each of the tissues\n",
    "# from what files are saved\n",
    "\n",
    "make_tissue_matrix_ready <- function (file, obj) {\n",
    "    filename        <- paste('../data',file,sep=\"/\")\n",
    "    logFC_mat       <- read.csv(filename)\n",
    "    logFC_mat       <- logFC_mat[order(rownames(logFC_mat)),]\n",
    "    logFC           <- as.matrix(as.numeric(logFC_mat$logFC),nrow=dim(obj)[2],ncol=1)\n",
    "    rownames(logFC) <- rownames(logFC_mat)\n",
    "    return(logFC)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_list <- lapply(X=filenames, FUN=make_tissue_matrix_ready, obj=reduced_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(matrix_list)\n",
    "logFC_mat = as.matrix(lapply(X   = matrix_list, \n",
    "                             FUN = cbind),\n",
    "                      nrow = dim(reduced_obj)[2], \n",
    "                      ncol = length(matrix_list))\n",
    "length(logFC_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tissue_name <- function (tissue_name) {\n",
    "            tissue <- str_replace(tissue_name,'_DGE.txt','')\n",
    "            return(tissue)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_list <- lapply(X=levels(tissue_shared_male_female), FUN=get_tissue_name)\n",
    "length(tissue_list)\n",
    "head(tissue_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logFC_mat = as.matrix(as.numeric(unlist(matrix_list[1]),nrow=dim(reduced_obj)[2], ncol=1))\n",
    "\n",
    "for (i in (2:length(matrix_list))) {\n",
    "    n = as.matrix(as.numeric(unlist(matrix_list[i]),nrow=dim(reduced_obj)[2], ncol=1))\n",
    "    logFC_mat = cbind(logFC_mat, n)\n",
    "}\n",
    "\n",
    "dim(logFC_mat)\n",
    "rownames(logFC_mat) = logFC_mat_rownames\n",
    "colnames(logFC_mat) = tissue_list\n",
    "head(logFC_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logFC_mat_NQ <- normalizeQuantiles(logFC_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(logFC_mat_NQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat <- as.matrix(cor(logFC_mat_NQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rownames(dist_mat) <- colnames(logFC_mat)\n",
    "colnames(dist_mat) <- colnames(logFC_mat)\n",
    "\n",
    "message(\"Saving dist_mat object\")\n",
    "saveRDS(object = dist_mat, file = \"../data/dist_mat.rds\")\n",
    "message(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(pheatmap)\n",
    "pheatmap(as.matrix(dist_mat),   fontsize = 6)\n",
    "hm.parameters <- list(dist_mat, fontsize = 6)\n",
    "do.call(\"pheatmap\", c(hm.parameters,  filename=\"../pdf/Figure1c.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "For replicability and reproducibility purposes, we also print the following metadata:\n",
    "\n",
    "1. Checksums of **'artefacts'**, files generated during the analysis and stored in the folder directory **`data`**\n",
    "2. List of environment metadata, dependencies, versions of libraries using `utils::sessionInfo()` and [`devtools::session_info()`](https://devtools.r-lib.org/reference/session_info.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Checksums with the sha256 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message(\"Generating sha256 checksums of the artefacts in the `..data/` directory .. \")\n",
    "system(\"cd ../data/ && sha256sum * > ../metadata/sha256sums.txt\", intern = TRUE)\n",
    "message(\"Done!\\n\")\n",
    "\n",
    "data.table::fread(\"../metadata/sha256sums.txt\", header = FALSE, col.names = c(\"sha256sum\", \"file\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Libraries metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_info <- devtools::session_info()\n",
    "message(\"Saving `devtools::session_info()` objects in ../metadata/devtools_session_info.rds  ..\")\n",
    "saveRDS(session_info, file = \"../metadata/devtools_session_info.rds\")\n",
    "message(\"Done!\\n\")\n",
    "\n",
    "message(\"Saving `utils::sessionInfo()` objects in ../metadata/utils_session_info.rds  ..\")\n",
    "saveRDS(session_info, file = \"../metadata/utils_info.rds\")\n",
    "message(\"Done!\\n\")\n",
    "\n",
    "session_info$platform\n",
    "\n",
    "session_info$packages[session_info$packages$attached==TRUE, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive artefacts in GitHub releases using **`{ropensci/piggyback}`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tarball of all the light .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message(\"Creating tarball of .csv files and removing files ..\\n\")\n",
    "system(\"cd ../data/ && tar -czvf csv.tar.gz *csv && rm *csv\", intern = TRUE)\n",
    "message(\"Done!\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new release in the repository of choice (or ignore if this cannot be completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to attempt archive creation via try or ignore and move on\n",
    "\n",
    "create_piggyback_archive <- function(repo, tag){\n",
    "        message(paste0(\"Trying to create a new tag in GitHub releases named \", tag_new, \" ..\\n\"))\n",
    "        piggyback::pb_new_release(repo = repo_archive, tag  = tag_new)\n",
    "        message(paste0(\"Done..!\\n\"))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(magrittr)\n",
    "\n",
    "tag_new      <- paste(\"figure1c\", system(\"git config user.name\", intern = TRUE), snakecase::to_snake_case(as.character(format(Sys.time(), \"%H\"))), sep = \"_\")\n",
    "repo_archive <- \"lifebit-ai/lifebitCloudOSDREgtex\"\n",
    "\n",
    "\n",
    "run_pb <- try(create_piggyback_archive(repo = repo_archive, tag = tag_new), silent = FALSE) \n",
    "\n",
    "if (class(run_pb) != \"try-error\") {\n",
    "    message(paste0(\"Uploading the following files to the GitHub Release with tag '\", \n",
    "                   tag_new,\n",
    "                   \"' (\", \n",
    "                   repo_archive, \n",
    "                   \"): \\n\\n\", \n",
    "                   paste0(paste(\"- \",list.files(\"../data/\"), collapse = \"\\n\"))), \"\\n\")\n",
    "    piggyback::pb_track() %>% piggyback::pb_upload(repo = repo_archive, tag = tag_new)\n",
    "    message(\"Done! \\n'\")\n",
    "    message(paste0(\"Paste the following link in your browser to look at the attached files to the GitHub Release (tag:\", tag_new, \") \\n\\n\", \n",
    "                   \"https://github.com/\", \n",
    "                   repo_archive, \n",
    "                   \"/releases/tag/\",\n",
    "                   tag_new, \"\\n\"))\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
